# -*- coding: utf-8 -*-
"""2- Classificação de Sentimentos com spacy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qWa4QS68-GVoBunblxzBdmxDSwNSZdmy

# Classificação de textos com spaCy

# Etapa 1: Importação e instalação das bibliotecas
"""

#!pip install spacy --upgrade
!pip install spacy==2.2.3

!pip install pt_core_news_sm

!python -m spacy download pt_core_news_sm

import spacy
import pt_core_news_sm

import pandas as pd
import string
import spacy
import random
import seaborn as sns
import numpy as np

"""# Etapa 2: Carregamento da base de dados"""

# Utilizando uma base de dados que mostra o texto e a emoção presente nele:
base_dados = pd.read_csv('/content/base_treinamento.txt', encoding = 'utf-8') # adicionar nos arquivos do colab

# Linhas e colunas:
base_dados.shape

# As primieras linhas da base de dados:
base_dados.head()

# As últimas linhas da base de dados:
base_dados.tail()

# Gráfico que conta o numero de registros por emoção:
sns.countplot(base_dados['emocao'], label = 'Contagem');

"""# Etapa 3: Função para pré-processamento dos textos, ou seja , limpeza do texto."""

pontuacoes = string.punctuation
pontuacoes

from spacy.lang.pt.stop_words import STOP_WORDS # utlizando as stopwords do spacy em portugues
stop_words = STOP_WORDS
print(stop_words)
len(stop_words)

import pt_core_news_sm # modelo spacy em portugues
pln= pt_core_news_sm.load()

# Função que vai

def preprocessamento(texto):
  texto = texto.lower() #converte o texto para minisculo
  documento = pln(texto)
  
  lista = []
  for token in documento:
    #lista.append(token.text) #retorna os tokens
    lista.append(token.lemma_) # retorna o lemma
  
  lista = [palavra for palavra in lista if palavra not in stop_words and palavra not in pontuacoes] # percorre toda a lista e tira as stopword e pontuações
  lista = ' '.join([str(elemento) for elemento in lista if not elemento.isdigit()]) # retorna em forma de frase e não em listas e remove os digitos

  return lista

teste = preprocessamento('Tentando fazer a classificação de sentimentos em texto com Spacy @ !')
teste

"""# Etapa 4: Pré-processamento da base de dados

### Limpeza dos textos
"""

# Antes:
base_dados.head(10)

base_dados['texto'] = base_dados['texto'].apply(preprocessamento) # aplicando o pré-procesamento na coluna texto

# Depois:
base_dados.head(10)

"""### Tratamento da classe"""

# 
exemplo_base_dados = [["este trabalho é agradável", {"ALEGRIA": True, "MEDO": False}],
                      ["este lugar continua assustador", {"ALEGRIA": False, "MEDO": True}]]

type(exemplo_base_dados) # tipo

exemplo_base_dados[0]

type(exemplo_base_dados[0][1])

# Percorre todo o registro para deixar a base de dados na mesma estrutura do Json:
base_dados_final = []
for texto, emocao in zip(base_dados['texto'], base_dados['emocao']):
  #print(texto, emocao) # texto +emoção
  # separando as emoções:
  if emocao == 'alegria': 
    dic = ({'ALEGRIA': True, 'MEDO': False})
  elif emocao == 'medo':
    dic = ({'ALEGRIA': False, 'MEDO': True})

  base_dados_final.append([texto, dic.copy()]) # criando a base final

len(base_dados_final) # tamanho

base_dados_final[0] #vendo como ficou

type(base_dados_final[0][1]) # tipo

# Resultado Final:
base_dados_final

"""# Etapa 5: Criação do classificador


"""

modelo = spacy.blank('pt') # criando um novo modelo em portugues
categorias = modelo.create_pipe("textcat") # tipo do modelo: categorização de texto
categorias.add_label("ALEGRIA") # categoria alegria
categorias.add_label("MEDO") # categoria medo
modelo.add_pipe(categorias) # adiciona as categorias no modelo
historico = [] # armazena os resultados

# Treinando o modelo:

modelo.begin_training() # inicia o treinamento
for epoca in range(1000): # ajustando os pesos dos dados (redes neurais), o algoritmo é executado por 1000 épocas
  random.shuffle(base_dados_final) # mistura os dados
  losses = {} # erro
  # Pega 30 registros, submete pra rede neural, faz o calculo do erro e depois faz o ajuste dos pesos, de batch em batch
  for batch in spacy.util.minibatch(base_dados_final, 30): # 7 batchs com 30 registros cada, ou seja, na primeira época do treinamento ele passa por todos os registros, mas o treinamento será de 30 em 30
    textos = [modelo(texto) for texto, entities in batch]# pega cada um dos textos e submete ao modelo para fazer uma previsão, tendo o calculo do erro, até que ele se adapte
    annotations = [{'cats': entities} for texto, entities in batch] # entities indica as categorias
    modelo.update(textos, annotations, losses=losses)
  if epoca % 100 == 0: # depois de executar todas as epocas, mostre o erro
    print(losses) # vizualiza o valor do erro
    historico.append(losses) # a cada época o erro diminui

# Uma lista só dos erros:
historico_loss = []
for i in historico:
  historico_loss.append(i.get('textcat'))

historico_loss = np.array(historico_loss) # matriz dos erros
historico_loss

# Criando um gráfico para analisar esse erro:
import matplotlib.pyplot as plt
plt.plot(historico_loss)
plt.title('Progressão do erro')
plt.xlabel('Épocas')
plt.ylabel('Erro')

# Não é necessario fazer tantas epocas pois o erro já reduz muito

modelo.to_disk("modelo") # salvando o modelo, para não ter quer treinar toda vez

"""# Etapa 6: Testes com uma frase"""

modelo_carregado = spacy.load("modelo") # trazendo o modelo criado anteriormente
modelo_carregado

texto_positivo = 'eu adoro a cor dos seus olhos'

texto_positivo = preprocessamento(texto_positivo) # passa o texto no pré-processamento (lemma)
texto_positivo

previsao = modelo_carregado(texto_positivo)
previsao

previsao.cats # essa frase indica 0.99 de alegria

# testando a mesma coisa só que em um texto negativo
texto_negativo = 'estou com medo dele'
previsao = modelo_carregado(preprocessamento(texto_negativo))
previsao.cats

"""# Etapa 7: Avaliação do modelo

## Avaliação na base de treinamento
"""

# Pedindo para o modelo classificar todas as frases da base de dados:

previsoes = []
for texto in base_dados['texto']:
  #print(texto)
  previsao = modelo_carregado(texto)
  previsoes.append(previsao.cats)

previsoes

# Mostrando uma matriz para mostrar o sentimento de cada frase:

previsoes_final = []
for previsao in previsoes:
  if previsao['ALEGRIA'] > previsao['MEDO']: #se o valor de alegria for maior, o sentimento é alegria
    previsoes_final.append('alegria')
  else:
    previsoes_final.append('medo')

previsoes_final = np.array(previsoes_final)

previsoes_final

respostas_reais = base_dados['emocao'].values # respostas da base, para comparar com o modelo
respostas_reais

# Trazendo o sklearn para determinar a acuracia entre o treinamento e o real:
from sklearn.metrics import confusion_matrix, accuracy_score
accuracy_score(respostas_reais, previsoes_final) 
# 100% de acuracia, pode ser overfitting

# Matriz de confusão: diagonal principal (acertos), primeira linha alegria e segunda linha medo:
cm = confusion_matrix(respostas_reais, previsoes_final)
cm

"""## Avaliação na base de teste como feito na base de treino"""

base_dados_teste = pd.read_csv('/content/base_teste.txt', encoding = 'utf-8')

base_dados_teste.head()

base_dados_teste['texto'] = base_dados_teste['texto'].apply(preprocessamento)

base_dados_teste.head()

previsoes = []
for texto in base_dados_teste['texto']:
  #print(texto)
  previsao = modelo_carregado(texto)
  previsoes.append(previsao.cats)

previsoes_final = []
for previsao in previsoes:
  if previsao['ALEGRIA'] > previsao['MEDO']:
    previsoes_final.append('alegria')
  else:
    previsoes_final.append('medo')

previsoes_final = np.array(previsoes_final)

respostas_reais = base_dados_teste['emocao'].values

accuracy_score(respostas_reais, previsoes_final)
#o real valor da acuracia é 0.54

cm = confusion_matrix(respostas_reais, previsoes_final)
cm
# é preciso trabalhar melhor esse algoritmo de redes neurais para aumentar a acuracia